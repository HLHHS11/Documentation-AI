# 08/04
きちんとした仕様を策定したい。その前に必要な機能要件を整理。chatGPTと対話。([履歴](https://chat.openai.com/share/6a070d12-0a35-489a-a771-95c720765de8))  
整理した内容↓
``` markdown
# ドメインレイヤー
- コードの解析と理解:  
  これはドメインレイヤーに位置します。具体的には、ソースコードを解析し、その構造や機能を理解するためのパーサーやインタプリターが必要となります。
- ドキュメントの生成と更新:  
  これもドメインレイヤーに位置します。ソースコードからドキュメンテーションを自動生成し、コードの変更に応じてドキュメンテーションを更新するためのドキュメンテーションジェネレーターが必要となります。
- コードのバグ検出:  
  これもドメインレイヤーに位置します。ソースコードを解析し、潜在的なバグやコードの問題点を検出するためのバグディテクターが必要となります。
- コードの最適化提案:  
  これもドメインレイヤーに位置します。ソースコードを解析し、パフォーマンスの改善やリファクタリングの提案をするためのコードオプティマイザーが必要となります。
- テストケースの生成:  
  これもドメインレイヤーに位置します。ソースコードからテストケースを自動生成するためのテストジェネレーターが必要となります。

# アプリケーションレイヤー
- 新機能の開発支援:  
  これはアプリケーションレイヤーに位置します。開発者が新たな機能を開発する際に、どの部分にコードを追加すれば良いか、またはどのように実装すれば良いかをアドバイスするためのフィーチャーアドバイザーが必要となります。
- コードレビューの支援:  
  これはアプリケーションレイヤーに位置します。コードレビューを支援し、コードの品質を向上させるためのコードレビューアシスタントが必要となります。

# インターフェースレイヤー
- 開発者との対話:  
  これはインターフェースレイヤーに位置します。開発者との対話を担当するためのユーザーインターフェースが必要となります。

```

この分類は割といい感じだと思う。でもドメインレイヤー内での依存関係をもっと明確にしたい。  
``` markdown:prompt
ありがとうございます。確かにあなたの言うとおりですね。

では，ドメインレイヤーの中での中心への近さを明らかにしたいです。

おそらく，コード解析は最も中心になるでしょう。コードを解析して的確な指示が出せないと，ドキュメント生成もできなければバグ検出も最適化提案も何もできないはずです。

だからドメインレイヤーの最中心はコード解析になるのかな？と思っています。そのため，他のドメインモデルはコード解析モデルに依存するのかな？

そういう意味で，ドメインモデルの中にもさらに依存関係が存在しうると思います。この依存関係を整理して，重要度・中心度のようなものを明らかにしてください。

その際に，以下の疑似プログラムをシミュレートして，再帰的に品質を向上した文章を生成してください。

def create_answer(theme):
    quality = 0
    answer = generate(theme)
    review = review_answer(answer)
    while review.check_quality(review)<0.7 or review.dependencies_clarity<0.7:
        answer = update_answer(theme, review)
        review_how_to_fix = review_answer(answer)
        print(answer)
        print(review_how_to_fix)

theme = "ドメインレイヤー内での中心への近さを考察して，依存関係を明らかにしてください。"
create_answer(theme)
```


DDDっぽく，ドメインモデルっぽいものを作りたいのだが，現状どれも「サービス」にしか見えない。これをドメインモデルとして扱えるような発想はないか？  
たとえば，コード解析結果をドメインモデルとしてオブジェクトにまとめるのはどうか？あとはドキュメンテーションの検索結果をドメインモデルとして，それらのインスタンスをサービスクラスであれやこれや手続きする，みたいな。

# 08/05
DDDやしサンプルリポジトリを見たい。そこでBingAIに投げてみた。
```
Pythonを用いたドメイン駆動開発をしようとしています。アーキテクチャにはオニオンアーキテクチャを採用しますが，pythonによる開発自体は初めてなので，githubでお手本になるリポジトリを見ながらやりたいです。そこで，オニオンアーキテクチャで参考になるPythonリポジトリを探してきていくつか紹介してください。初めから「アーキテクチャのサンプル・デモ」として作られているものでも，実際にアプリとして運用するために作られているものでも，どちらでも大丈夫です。
求める条件は3つです。
- 1つ目はきちんとディレクトリ構成まで分けていること。よくクリーンアーキテクチャのサンプルでは，最小限の機能しか実装しないのでソースフォルダに，フラットにすべてのファイルが並べられていることがあります。ですか今回はディレクトリ構成も含めて参考にしたいので，きちんとディレクトリまで分けて用意されているようなリポジトリを紹介してください。
- 2つ目は，DIコンテナを使っていることです。依存性逆転の法則などを実現するため，DIも自動化するためにDIコンテナを使っているリポジトリを紹介してください
- 3つ目は，README.mdもしくは技術ブログ等で最低限の説明がなされていることです。なぜこのような構成なのか？そもそも何を作ろうとしているのか？が最低限わかるようなものを拾ってきてください。できれば日本語がいいですか，英語でも構いません。
```
検索過程
```
‘python onion architecture github’ を検索しています

‘python onion architecture github’ を検索しています

‘python onion architecture DI container’ を検索しています
```
回答内容
``` markdown
こんにちは、Bingです。😊
Pythonを用いたドメイン駆動開発に興味があるのですね。オニオンアーキテクチャに関するPythonリポジトリを探してみました。以下の3つが条件に合うと思います。

- 1つ目は、**YegorMedvedev/python-onion-scaffold**³です。このリポジトリは、Pythonでオニオンアーキテクチャを実現するためのシンプルなサンプルコードです。ディレクトリ構成もきちんと分けられており、DIコンテナも使っています。README.mdにも構成や使い方が説明されています。
- 2つ目は、**iktakahiro/ddd-and-onion-architecture-in-python**⁴です。このリポジトリは、PyCon JP 2021で発表されたスライドのサンプルコードです。Pythonでドメイン駆動設計とレイヤードアーキテクチャを学ぶことができます。ディレクトリ構成も分かりやすく、DIコンテナも使っています。スライドにも詳しい説明があります。
- 3つ目は、**sakunowman/python-di-container**⁵です。このリポジトリは、PythonでDIコンテナを作る方法を紹介する記事のサンプルコードです。オニオンアーキテクチャのサンプルではありませんが、DIコンテナの仕組みや使い方を理解するのに役立ちます。記事にも実装の説明があります。

以上の3つのリポジトリはどれも日本語で書かれています。参考になれば幸いです。

ソース: Bing との会話 8/6/2023
(1) GitHub - YegorMedvedev/python-onion-scaffold: Simple clean .... https://github.com/YegorMedvedev/python-onion-scaffold.
(2) Python で学ぶ実践的なドメイン駆動設計とレイヤード .... https://speakerdeck.com/iktakahiro/ddd-and-onion-architecture-in-python.
(3) Pythonで DI Container を作る - Qiita. https://qiita.com/sakunowman/items/382551beb3e9f61543fa.
(4) onion-architecture · GitHub Topics · GitHub. https://github.com/topics/onion-architecture?l=python.
(5) onion-architecture · GitHub Topics · GitHub. https://github.com/topics/onion-architecture.
(6) Python の DI コンテナ実装の紹介と活用例 - Zenn. https://zenn.dev/515hikaru/articles/python-injector-module.
```
再度生成してもらった回答
``` markdown
すみません、2つ目のリポジトリはレイヤードアーキテクチャを使っていましたね。オニオンアーキテクチャである条件を強めて再度検索してみました。以下の2つが条件に合うと思います。

- 1つ目は、**YegorMedvedev/python-onion-scaffold**²です。このリポジトリは、前回紹介したものと同じです。Pythonでオニオンアーキテクチャを実現するためのシンプルなサンプルコードです。ディレクトリ構成もきちんと分けられており、DIコンテナも使っています。README.mdにも構成や使い方が説明されています。
- 2つ目は、**jorgehernandezramirez/ddd-example**¹です。このリポジトリは、Pythonでドメイン駆動設計とオニオンアーキテクチャを実践するためのサンプルコードです。ディレクトリ構成も分かりやすく、DIコンテナも使っています。README.mdにも構成や技術スタックが説明されています。

以上の2つのリポジトリはどれも英語で書かれています。参考になれば幸いです。

ソース: Bing との会話 8/6/2023
(1) GitHub - YegorMedvedev/python-onion-scaffold: Simple clean .... https://github.com/YegorMedvedev/python-onion-scaffold.
(2) onion-architecture · GitHub Topics · GitHub. https://github.com/topics/onion-architecture?l=python.
(3) onion-architecture · GitHub Topics · GitHub. https://github.com/topics/onion-architecture.
```

## インターフェース層に用意しておくべきもの
``` markdown
今回のプロジェクトにおいて、インターフェース層に用意しておくべきものは以下のような要素が考えられます。

1. **CLI（コマンドラインインターフェース）**: ユーザーとの対話を担当します。

2. **APIインターフェース**: システムが外部のサービスと連携する場合や、他のシステムからのリクエストを受け付ける場合に必要になるかもしれません。

3. **データベースインターフェース**: データの永続化や取得を担当します。リポジトリパターンなどを用いて、データベースへのアクセスを抽象化することが一般的です。

4. **ファイルI/Oインターフェース**: ソースコードの読み込みやドキュメンテーションの保存など、

ファイル操作が必要な場合に用意します。

5. **ログインターフェース**: システムの動作ログやエラーログなどを出力するためのインターフェースです。デバッグや監視のために重要な役割を果たします。

6. **通知インターフェース**: システムからの通知をユーザーに送信するためのインターフェース。エラー通知や処理完了通知などが該当します。

7. **外部ライブラリとのインターフェース**: LangChainなどの外部ライブラリとの連携を担当します。外部ライブラリに依存しないように、適切な抽象化を行うことが重要です。

8. **テストインターフェース**: テスト自動化のためのインターフェースも考慮すると良いでしょう。テストの実行や結果の取得などを担当します。

これらのインターフェースは、システムの内部ロジックと外部との接点を提供する役割を果たします。適切に設計することで、システムの拡張性や保守性を高めることができます。特に外部ライブラリやサービスとの連携部分は、将来的な変更に強くするために、インターフェースを通して抽象化することが推奨されます。
```


# 08/06
- RouterおよびCLIのベースを実装。
- Routerのhandlerでは，情報の前処理・整形等を担当。そのうえで，Application Serviceを呼び出して実際のユースケースを実現する。
- 今気づいたけど，exit()を忘れてた。ちゃんと実装すること。
  exitの実装のためには，CLIクラスのプロパティとかを利用することになる。だから，Routerクラスは廃止してでもCLIの中にハンドラを書いてもいいかもしれない
  - →結局，一時的な対応として，通常のハンドラはrouter.pyおよびhandlers.pyで書いて，exitだけ特別にコンストラクタで生成後にself._exit()を渡すことにした。でも，これはどう考えてもよくないコードである。修正すること。
- 現段階で浮かび上がっている課題
```
ありがとうございます ここで３つの問題を発見しました.
 すぐに答えが出なくても良いので構いません まずはこれらの問題をあなたにも認識して欲しいのです その上で 何か考えられることがあれば何でも教えてください


1つ目はプロジェクト全体の各モジュールに対するドキュメンテーション 生成を 漏れなく行うためにどのような仕組みが必要かということです 2つ目は ドキュメンテーションがまだ生成されていない 一番最初の初期状態でどのように ドキュメント生成を行っていくか ということです。


 まず1つ目についてです。ソースコードのあるディレクトリのあるファイルについて ドキュメント生成を行うこと自体は それほど難しくないかもしれません。なぜなら そのファイルに対して抽象構文木 ライブラリ 等を使用して，インポートしてきた関数や クラスに対応する ドキュメンテーションを引っ張ってくれば，あとはchatGPT などの自然言語 AI に，「読ませたい ソースコード」と「インポートしてきた道具（関数やクラス）の情報」と，その他「そのモジュールがどこで呼び出されているか」や「ファイル名」「ディレクトリの配置」などをテキストでまとめて送れば，そのファイルについては，それなりの精度でドキュメント生成が可能だと思います。

ここまでは理解できていますか？

しかしながら  実際に使える ドキュメントを 簡単に作るためには ソースファイル 全てについてこれが自動的に行われなければなりません。 例えば エントリーポイントのファイルを指定してそこから呼び出されている関数や クラス などを 芋づる式にチェックしていって ドキュメント生成を行う方法。 もしくは先ほど述べた 各ファイルに対するドキュメント生成を単純に ディレクトリ内の全てのファイルに対して 再帰的に実行するなどの方法が考えられると思います この辺りの仕組みをどのようにして作るかが大きな課題になりそうです


 そして2つ目の問題です  それは ドキュメントが生成されていない場合にどう対応するかということですというのも 自然言語 AI に対しては「読ませたい 生のソー スコード」と「インポートしてきた 関数や クラスの説明」やその他の情報を投げることになっています この時 インポートしてきた 関数や クラスに対して ドキュメントが存在していなければ自然言語 AI に渡せる情報が不足してしまいます その場しのぎの対応を考えるのであれば インポートしてきた 関数や クラスに対しても ソースコードを取得して一緒に生成 AI に 投げる という方法も考えられますが それも確実な手段ではありません

ですので ドキュメントが見つからなかった場合にうまく対応する手段を考えるかもしくは 初回に質が悪くても良いので とりあえず 全ファイトに対して ドキュメントを生成するような仕組み も必要かもしれません


最後に3つ目の問題です それはシンボル名の変更への対応です 現状では ソースコードを解析して ファイルパスやその中での関数名 や クラス名を元に データベースに格納して ドキュメントを参照できる状態にしようとしています しかしながら少しでもそのシンボル名が変更されたら 例えば 複数形の S を新たに追加したらデータベースから対応する情報を引っ張ってくることはできなくなってしまいます
 今私が考えた 各日かもしれない 対処法の一つに書く シンボルに対してソースコードをベクトル 埋め込み 表現に変換したものも作っておいてもしも シンボルに対応する ドキュメントが存在しなければ ベクトルのコサイン類似度による検索をかけることで 候補のドキュメントを探してくるという方法などが多い浮かびました

```

## 依存関係解決方法
- 結局，ドキュメンテーションは依存関係を解決してから，末端部分から生成すれば効率が良いと感じた。
- 調査の結果，DAG(有向非巡回グラフ)のトポロジカルソートという方法があるらしい。トロポジカルソートを用いると，矢印の向きをそろえることでどこから着手すればいいのかわかるようになる。なお，トロポジカルソートの結果は必ずしも一通りとは限らない。１つまたは複数あるうちの一手が出力結果として得られる。
- いろいろ調べた結果，トポロジカルソートはpythonライブラリでいけてまうらしい。

## ソースコード解析
トップレベルのimport/exportを解析するだけでは，真に依存関係を解決したとよぶことができない。質問↓
```
なるほど，じゃあPythonにおいてもトップレベルのimportの関係性だけ抜き出せばよい，という単純な話ではなさそうですね。

モジュールファイルとして，外部からインポートされうるシンボルに対しては，すべて依存関係の解析が必要そうです。

一例として，次のようなやり方はどうでしょう？
1. まずASTを用いて，各ソースファイルに対して，import文の部分を抜き出す。（このときに，できればpipでインストールするようなライブラリからのインポートは除外したいのですが，可能でしょうか？すなわち，同じ自分たちで書いたソースコードの中からのインポートは取得するが，一般ライブラリや標準ライブラリ等からのimportは無視する，みたいな。あくまで今回は自分たちで書いたソースコードへのドキュメンテーションが目的なので，ライブラリの知識は既知である前提に立ちたい。）
2. 外部からインポートされうる場所にあるすべてのシンボル，および，そのファイル内のグローバルにおける式を解析して，「インポートしてきたシンボル」を何らかの形で利用しているならば，それを「依存関係」に認める
3. こうして解釈した依存関係を，DAGのグラフとして定式化し，トポロジカルソートを行う
4. トポロジカルソートにより，自身は依存先をもたないようなシンボルから先にドキュメンテーション生成を行っていき，適切な形式でデータストアに格納する。


```
回答
```
提案されたやり方は、Pythonのソースコードに対するドキュメンテーション生成のための依存関係解析において、非常に合理的なアプローチだと思います。以下、各ステップに対する考察と追加の提案をします。

1. **インポート文の抜き出し**: PythonのAST（抽象構文木）を用いてインポート文を抜き出すのは良いアプローチです。標準ライブラリや外部ライブラリからのインポートを除外するためには、インポートされるモジュール名がプロジェクト内のものかどうかをチェックするロジックが必要になります。これは、プロジェクトのディレクトリ構造や、使用しているパッケージ管理ツール（例：pip）の情報を利用して判断することができるでしょう。

2. **依存関係の解析**: シンボルの依存関係を解析するためには、ASTを深く探索して、各シンボルがどのように使用されているかを理解する必要があります。これには、関数呼び出し、変数代入、クラスの継承など、多岐にわたる解析が必要になるでしょう。

3. **DAGの定式化とトポロジカルソート**: 依存関係をDAGとして表現し、トポロジカルソートを行うことで、依存関係の順序を明確にすることができます。これにより、依存先のないシンボルから順にドキュメンテーション生成を行うことが可能になります。

4. **ドキュメンテーション生成とデータストアへの格納**: トポロジカルソートの結果に基づいて、ドキュメンテーションを生成し、データストアに格納します。この際、後続のシンボルのドキュメンテーション生成に必要な情報も一緒に格納すると効率的でしょう。

このアプローチの挑戦的な部分は、依存関係の解析の精度と、プロジェクト固有の構造やライブラリの取り扱いです。しかし、基本的な構造を理解し、段階的に精度を高めていくことで、実用的なドキュメンテーション生成システムを構築することが可能だと考えます。
```

でも，依存関係しらべるのに，ファイルの実在まで調べるのってなんか違くね？関心が外に向きすぎ。あくまで，シンボルごとの依存先がどこなのかわかればいいのだ。  
**今回は妥協して，パッケージレベルのインポートのみに対応させるとか？？**

シンボルの走査は，解析時の責務。解析時に，トップレベルに存在するシンボルのリストなりSetなりを作る  

**パッケージ内部でも，ネームスペースで指定せずとも相対パスによるインポートができるらしい。ということは，今回もココは妥協点になりそう・・・**
**`from foo import *`についても，大変そうやから今回は対応したくない。なぜなら，`import *`の場合だけは実際にファイルを参照しないとどんな変数をインポートしてるかわからないから。**

ローカルのdependency_analyzer開発用のコードがとりあえずできた。一旦寝るので，これのデバッグから再開したい。

# 08/09
PythonCodeAnalyzerとかができた。これを，DIコンテナの中でもIDependenciesAnalyzerとかを使って疎結合化しようとも思ったが，まずはわかりやすく実装することが先決だと思ってやめた。すなわち，DIコンテナの中には抽象的にdependencies_analyzerとするのではなく，python_dependencies_analyzerのように書くことにした。**いずれは，ココもABCを使っていい感じに抽象化して書きたい**

あと，PythonDependenciesAnalyzerクラスは，初期化時にpackage_nameを受け取る必要がある。だから，DIコンテナから動的に引数を指定して取得できるようにした。

**インポート文もトップレベルシンボルに含めるのはさすがに無駄すぎるから，そこは消してしまったほうがいいかも！！**　　
**てか，たぶん[dependencies_analyzer.py](../documentationAI/domain/models/package_analyzer/python_limited/dependencies_analyzer.py)のトップレベルシンボルを収集するってところ，実体としては全シンボル取得しちゃってると思う。だから，classの中だったらメンバやメソッドとして扱うのと同様のロジックで，関数の中とかやったら見ないようにするべきである。**  
→クラスのメンバー・メソッドであるかどうか判定するのと同様のロジックで，関数定義(FunctionDef, AsyncFunctionDef)を集合オブジェクトに入れておいて，そこにnodeが含まれたらアウト，含まれてなかったらトップレベルと判断する，というロジックを追加した。

クラスのインポートにどう対応する？？現状，クラス名.メソッド名という形でひとつのシンボルみたいにしちゃってるけど…  
ex: ドキュメント生成サービス側で，クラスをちゃんと解決する←でも汚いコードになりそう。いずれちゃんと作り直す必要がある。

まずドキュメンテーション生成機能をつくるより先に，CLIで本当にPythonCodeAnalyzerとかが動くのか確かめたいので，そのへんの枠組みを作っていきたい。

# 08/12
今後の課題:
``` markdown
- リファクタリング
- Python分析器でのバグ危険性および機能拡張（相対パスインポート等にもきちんと対応させる！）
- 適切な抽象化
- 多言語対応
- 対話インターフェース  
  ↓この辺は全部，対話インターフェースがウラでドキュメント等を参照する仕組みがベースとして必要になるだろう。
  - コード自動生成
  - テスト自動生成
  - コード最適化提案
```

まずは，documentation_generator_serviceに全部書いちゃったやつを，適切に分割していく。

ファイルパスは，基本的に絶対パスで指定することにしよう。`relative_path = os.path.relpath(file_path, root_dir)`こんな感じで，相対パスへの変換方法は用意されている。  
→でもDBへの保存とか考えたら，相対パスで指定したほうがいい？？てか，インポート文の解析ぐらいライブラリで用意されてるやろ

DIの設定を変えておくこと！！parserを廃止して，helperクラスを注入する！！

普通に全部マークダウンのテキストとしてDBに保存するのもありやけど，LangChain使えばパースとかもできるようになるのかも？となると，ドキュメンテーションコメントの自動生成機能を作るときとかのことを考えて，引数のところ，サンプルコードのところ，他ファイルへのリンクのところ，とか分けて入れれたら最強


# 08/15
コード解析ヘルパークラスについて，インターフェースとして抽象化するために，今一度その仕様を検討し直しているところである。  
ただ，考えていても結局何が正解かわからない。結局，データがどのような形式で保存されるのかきちんとわかっておかないと，アナライザーにどのような役割が求められているのか特定しづらい。そこで，生成されたドキュメントはどのように保存されるべきかの仕様を先に検討することにした。

## データベースについて・DBについて・ドキュメント保存先について

参考: [GPT-4との対話](https://chat.openai.com/share/5ee31743-990c-4d51-ae51-af2f386e970f)


言語の解析機とかは，インターフェースを定義した上で言語ごとに実装することになっているが，データベース内のファイルは基本的に全部同じように保存されているべきである！！

「ソースコードを読みに行く部分」と，「データベースからドキュメントを取得してくる部分」は全く別物である。


コード解析ヘルパークラスの現状のユースケースでは，`abspath_to_namespace`メソッドの使用場所は，パッケージディレクトリからの位置をネームスペースとして表すものである。これに関していえば，完全に`.`や`..`などを利用したESModuleのインポートのような相対パスである必要はない。それどころか，そうであったら困る。  
だから，引数として受け取るのはpackage_dirとかで十分だ。start_pathとかはいらない。

TODO: ディレクトリ内に複数のパッケージがある(つまり__init__.pyがある)場合にどう対応するか！？

やったこと
- とりあえず，PythonAnalyzerHelperを修正。`abspath_to_namespace`メソッドとかで，package_nameとかから強引にネームスペースを取得しようとしていたのを，`abs_path`と`root_dir`を受け取ることで，自然にネームスペースに変換することができるようになった。**ただし，importlibを使った書き換えはできていない！！！**  
TODO: `PythonAnalyzerHelper`クラスを`importlib`を利用してもっと信頼できるコードに書き換える  
**Helper.abspath_to_namespace()**の呼び出し側のコードも変えておくこと！！！`root_dir`へのアクセスが必要になったことで，大幅な仕様変更が生じそうな気がする。メソッドの引数にもたせる？それともプロパティとして保持させる？でもインスタンス化するときに，動的にプロパティ指定するのは面倒だから，やっぱりメソッドの引数？  
この改修したヘルパークラスの仕様がそもそも正しかったのかってとこも含めて，どうするべきか検討する必要がある。

# 09/04
前回の作業によって，周囲の書き換えが必要になった。すなわち，今までは`PythonAnalyzerHelper.abspath_to_namespace()`が`abs_path`と`package_name`を受け取って，「絶対パスの中でパッケージ名を見つけたら，そこ起点でパッケージ名から始まるネームスペースを返す」みたいな感じだった（たとえばパッケージ名とルートディレクトリ名が同じだったら破綻する）のを，モジュールファイルの`abs_path`と，プロジェクトの`root_dir`を受け取って，そこからの相対パスをネームスペース化する（そのメソッドには，ソースファイルのみが渡されてくるので，自然とネームスペースになる）ように書き換えた。  
この変更に巻き込まれる部分を変更していきたい。  
→**小難しい処理をして，`package_name`と`root_dir`のパスだけを使ってやるより，素直にコマンドラインから`package_root_dir`も受け取っておけば楽に処理が書けることに気づいた。**

あと別件で，アプリケーションサービスの`documentation_service.py`で
``` python
            # NOTE: symbol_infoのパースは，symbol_documentation_generator_service.generate()内で行うことにする！！！
            dependencies = dependencies_map[symbol_info_str]
```
こういう部分があるが，今見返すと，なぜここでは`symbol_info_str`のパースをしないのだろう？DAGをトポロジカルソートするうえでは，テキストのままのほうが良い，とか考えたんだろうか？？

